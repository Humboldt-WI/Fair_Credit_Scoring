{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAIR POST-PROCESSING\n",
    "\n",
    "This notebook implements the Reject Option Classification post-processor [(Kamiran et al. 2012)](https://ieeexplore.ieee.org/abstract/document/6413831).\n",
    "\n",
    "The notebook applies reject option classification post-processir to classifier predictions. It loads the data exported in `code_00_partitinoing.ipynb` and predictions of base classifers produced in `code_08_postprocess1.R`. The post-processed predictions are exported as CSV files. A further analysis of the processor outputs is performed in `code_12_postprocess5.R`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Parameters and preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PARAMETERS\n",
    "\n",
    "# working paths\n",
    "%run 'code_00_working_paths.py'\n",
    "\n",
    "# specify data set\n",
    "# one of ['bene', 'german', 'uk', 'taiwan', 'pkdd', 'gmsc', 'homecredit']\n",
    "data = 'taiwan' \n",
    "\n",
    "# partitioning\n",
    "num_folds = 5\n",
    "seed      = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### POST-PROCESSOR PARAMS\n",
    "\n",
    "metric_name      = 'Statistical parity difference'\n",
    "num_class_thresh = 100\n",
    "num_ROC_margin   = 50\n",
    "all_bound        = [0.1, 0.2, 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PACKAGES\n",
    "\n",
    "import sys\n",
    "sys.path.append(func_path)\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from load_data import *\n",
    "\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.algorithms.postprocessing.reject_option_classification import RejectOptionClassification\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### RANDOM SEED\n",
    "\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 186)\n"
     ]
    }
   ],
   "source": [
    "##### LOAD PARTITIONING\n",
    "\n",
    "dataset_orig_test = pickle.load(open(data_path + 'prepared/' + data + '_orig_test.pkl', 'rb'))\n",
    "te                = dataset_orig_test.convert_to_dataframe()[0]\n",
    "print(te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### DATA PREP\n",
    "\n",
    "# protected attribute\n",
    "protected           = 'AGE'\n",
    "privileged_groups   = [{'AGE': 1}] \n",
    "unprivileged_groups = [{'AGE': 0}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fair processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "- FOLD 0...\n",
      "------------------------------\n",
      "-- BOUND 0.1...\n",
      "-- BOUND 0.2...\n",
      "-- BOUND 0.3...\n",
      "\n",
      "------------------------------\n",
      "- FOLD 1...\n",
      "------------------------------\n",
      "-- BOUND 0.1...\n",
      "-- BOUND 0.2...\n",
      "-- BOUND 0.3...\n",
      "\n",
      "------------------------------\n",
      "- FOLD 2...\n",
      "------------------------------\n",
      "-- BOUND 0.1...\n",
      "-- BOUND 0.2...\n",
      "-- BOUND 0.3...\n",
      "\n",
      "------------------------------\n",
      "- FOLD 3...\n",
      "------------------------------\n",
      "-- BOUND 0.1...\n",
      "-- BOUND 0.2...\n",
      "-- BOUND 0.3...\n",
      "\n",
      "------------------------------\n",
      "- FOLD 4...\n",
      "------------------------------\n",
      "-- BOUND 0.1...\n",
      "-- BOUND 0.2...\n",
      "-- BOUND 0.3...\n",
      "\n",
      "\n",
      "Finished in 60.05 minutes\n"
     ]
    }
   ],
   "source": [
    "##### MODELING\n",
    "\n",
    "# timer\n",
    "cv_start = time.time()\n",
    "\n",
    "# base models\n",
    "model_names = ['glm', \n",
    "               \"rf\", \n",
    "               \"xgbTree\", \n",
    "               \"nnet\"]\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(num_folds):\n",
    "    \n",
    "    ##### LOAD DATA\n",
    "    \n",
    "    # feedback\n",
    "    print('-'*30)\n",
    "    print('- FOLD ' + str(fold) + '...')\n",
    "    print('-'*30)\n",
    "\n",
    "    # import data\n",
    "    data_train = pickle.load(open(data_path + 'prepared/' + data + '_scaled_' + str(fold) + '_train.pkl', 'rb'))\n",
    "    data_valid = pickle.load(open(data_path + 'prepared/' + data + '_scaled_' + str(fold) + '_valid.pkl', 'rb'))\n",
    "    data_test  = pickle.load(open(data_path + 'prepared/' + data + '_scaled_' + str(fold) + '_test.pkl',  'rb'))\n",
    "\n",
    "\n",
    "    ##### MODELING\n",
    "    \n",
    "    # import prediction results from R\n",
    "    dataset_trainResults_valid = pd.read_csv(res_path + 'intermediate/' + data + '_' + str(fold) + '_POST_training_results_dval.csv')\n",
    "    dataset_trainResults_test  = pd.read_csv(res_path + 'intermediate/' + data + '_' + str(fold) + '_POST_training_results_dtest.csv')\n",
    "    \n",
    "    # copy preds\n",
    "    dataset_orig_valid_pred = data_valid.copy(deepcopy = True)\n",
    "    dataset_orig_test_pred  = data_test.copy(deepcopy  = True)\n",
    "    \n",
    "    \n",
    "    # loop through bound values\n",
    "    for i in all_bound:\n",
    "        \n",
    "        # feedback\n",
    "        print('-- BOUND ' + str(i) + '...')\n",
    "    \n",
    "        # placeholder\n",
    "        ROC_test = pd.DataFrame()\n",
    "\n",
    "        # loop through base classifiers\n",
    "        for m in model_names:\n",
    "\n",
    "            # extract validation preds\n",
    "            scores_valid = np.array(dataset_trainResults_valid[m + '_scores']).reshape(len(dataset_trainResults_valid.index),1)\n",
    "            labels_valid = np.where(dataset_trainResults_valid[m + '_class'] == 'Good', 1.0, 2.0).reshape(len(dataset_trainResults_valid.index), 1)\n",
    "\n",
    "            # extract test preds\n",
    "            scores_test = np.array(dataset_trainResults_test[m + '_scores']).reshape(len(dataset_trainResults_test.index),1)\n",
    "            labels_test = np.where(dataset_trainResults_test[m + '_class'] == 'Good', 1.0, 2.0).reshape(len(dataset_trainResults_test.index), 1)\n",
    "\n",
    "            # write predictions\n",
    "            dataset_orig_valid_pred.scores = scores_valid\n",
    "            dataset_orig_valid_pred.labels = labels_valid\n",
    "            dataset_orig_test_pred.scores  = scores_test\n",
    "            dataset_orig_test_pred.labels  = labels_test\n",
    "\n",
    "            # fit ROC\n",
    "            ROC = RejectOptionClassification(unprivileged_groups = unprivileged_groups, \n",
    "                                             privileged_groups   = privileged_groups, \n",
    "                                             num_class_thresh    = num_class_thresh, \n",
    "                                             num_ROC_margin      = num_ROC_margin,\n",
    "                                             metric_name         = metric_name,\n",
    "                                             metric_ub           = i, \n",
    "                                             metric_lb           = -i)\n",
    "            ROC = ROC.fit(data_valid, dataset_orig_valid_pred)\n",
    "\n",
    "            # predict test scores\n",
    "            dataset_transf_test_pred    = ROC.predict(dataset_orig_test_pred)\n",
    "            ROC_test[m + \"_fairScores\"] = dataset_transf_test_pred.scores.flatten()\n",
    "            label_names                 = np.where(dataset_transf_test_pred.labels == 1, 'Good', 'Bad')\n",
    "            ROC_test[m + \"_fairLabels\"] = label_names\n",
    "\n",
    "        # export CSV\n",
    "        ROC_test.to_csv(res_path + 'intermediate/' + data + '_' + str(fold) + '_ROC_' + str(i) + '_predictions_test.csv', index = None, header = True)\n",
    "        \n",
    "    # feedback\n",
    "    print('')\n",
    "\n",
    "# print performance\n",
    "print('')\n",
    "print('Finished in {:.2f} minutes'.format((time.time() - cv_start) / 60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
